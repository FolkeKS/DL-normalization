
#+title: Run the project
#+author: Guillaume Coulaud
#+email: guillaume.coulaud33@orange.fr
#+language: en
#+date: <2022-08-26 fri 12:00>
#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/theme-readtheorg.setup
#+OPTIONS: toc : nil num : nil html - style : nil
#+options: timestamp:nil
#+OPTIONS: ^:nill
#+OPTIONS: _:nill

The context for this work is described in [[https://arxiv.org/abs/2312.05068][a paper on arXiv]], and the associated dataset is available [[https://kaggle.com/datasets/e6e1e745161300b59a7ecf7695f02fedd5ab6f5853067004c127029d15fde68e][here]]. 

* Install the project
#+BEGIN_SRC bash
git clone https://github.com/FolkeKS/DL-normalization.git
#+END_SRC

* Set up conda environment:

** Create the environment (might be slow):
#+BEGIN_SRC bash
conda env create --file environment.yml
#+END_SRC
- If the installation is stuck on ~Solving environment: |~ try:
#+BEGIN_SRC bash
conda config --set channel_priority strict
#+END_SRC
- Revert with:
#+BEGIN_SRC bash
conda config --set channel_priority true
#+END_SRC
** Activate the environment:
#+BEGIN_SRC bash
conda activate DL-normalization
#+END_SRC
** Setup project:
#+BEGIN_SRC bash
pip install -e .
#+END_SRC

* Set up wandb for experiment tracking:


  - Sign up at https://wandb.ai/site and log in
  - Find your API-key at https://wandb.ai/authorize
  - With your conda environment activated, run the following command and provide API-key
#+BEGIN_SRC bash
wandb login
#+END_SRC

* Train a model :
** On a computer
#+BEGIN_SRC bash
python scripts/trainer.py fit --config  configs/cnn_block.yaml
#+END_SRC

** On a cluster using SLURM

#+BEGIN_SRC bash
sbatch scripts/train.bash
#+END_SRC

** Configurations
    The configurations can be modified in the yaml files in [[file:configs/]]
    The model part, shown below, describes the parameter to instantiate the class CNN in [[file:src/cnn.py]].
    #+begin_src python

#+BEGIN_SRC python
class CNN(pl.LightningModule):
    def __init__(self,
        n_blocks: int = 4,
        n_blocks_filters: int = 64,
        layers_per_block: int = 2,
        kernel_size: int = 3,
        n_channels: int = 4,
        n_classes: int = 1,
        q: float = 0.9999,
        standarize_outputs: bool = False,
        predict_squared: bool = False,
        predict_inverse: bool = False,
        loss_fn: str = "masked_mse",
        padding_type: str = "valid",
        optimizer: str = "Adam",
        data_dir: str = "data/processed/newdata/",
        ,**kwargs):
#+END_SRC

    The data part describes the parameter to instantiate the class DirLightDataset in [[file:src/data/dataset.py]]

#+BEGIN_SRC python
class DirLightDataset(pl.LightningDataModule):
    def __init__(self,
        batch_size: int = 1,
        data_dir: str = "data/processed/newdata/",
        num_workers: int = 0,
        gpus: int = 0):
#+END_SRC

    - In order to make deterministic runs we set put =seed_everything: 42= (line 1) and ~deterministic: true~ (line 78).
    - To continue a run after it has been stopped we set  ~ckpt_path: "results/wandb/cnn/36c5vu01/checkpoints/last.ckpt"~ (line 115). With ~"cnn/"~ the wandb project in which the run was created, and ~"36c5vu01"~ the 'id' of the run. We also set ~version: 36c5vu01~ (line 11) to make wandb continue the training in the run instead of creating a new run. The ~global_step~ variable will be reset, so the charts must be visualized with ~epoch~ or ~step~ as x-axis.
    - It is also possible to choose how the best checkpoint is selected (lines 20-35), we choose the checkpoint that minimizes the loss in validation, but other choices are possible as choosing the one minimizing the quantile. However, we have not found how to use two strategies for the same run.
* Modify the code
    The model is loaded in scripts/trainer.py. Modifications are to be done in the config file but there are also modifications to make in the module loading the data in [[file:src/data/dataset.py]]:
    - adjust the padding, by default the padding is 31 for the latitude and 28 for the longitude. The images are cropped on the fly, the dimension of the image taken by the CNN is $4 \times (292+2\ell) \times (360 + 2\ell)$ with $\ell$ the number of layers
    - adding the sign distance map
    For computational time, these modifications should be made to the data directly before starting the training.

#+BEGIN_SRC python
class DirDataset(Dataset):
    def __getitem__(self, i):
        idx = self.ids[i]
        X_files = glob.glob(os.path.join(self.X_dir, idx+'.*'))
        Y_files = glob.glob(os.path.join(self.Y_dir, idx+'_norm_coeffs.*'))
        #Load the input / true data
        X = torch.from_numpy(np.load(X_files[0])['arr_0']).float()
        Y = torch.from_numpy(np.load(Y_files[0])['arr_0']).float()
        #Load the distance map
        distance_map = np.load("data/python_sign_dist_map_std.npz")['arr_0']
        distance_map = torch.from_numpy(distance_map).float()
        #Crop the input data
        distance_map = transforms.CenterCrop([200, 360+2*10])(distance_map)
        X = transforms.CenterCrop([200, 360+2*10])(X)
        #Add the distance map
        X = torch.cat((X,torch.unsqueeze(distance_map, 0)),0)
        return X, \
            Y
#+END_SRC


* Computing the metrics on the test data set


    To compute the metrics the test data had to be destandardized and then restandardized. All the data are standarized using the 10 training samples.
    We compute the mean and standard deviation of the mean/max/quantile 99,99% of the absolute relative error over the test dataset. We save the tensor of the relative error for each sample and save an image of the mean of the relative error. The code and results are in the repository [[file:results/test_metrics/]] each repository corresponds to a data set. To run the computation of the metrics, run the Python script from the root directory of the project. The configuration of the runs is added to a list ~model_params~, each element of this list is a list with the index corresponding to:
    1) [@0] Boolean: compute or not the metrics
    2) Boolean: whether the run uses the sign distance map
    3) Numpy array: the sign distance map
    4) Int: number of layers
    5) Class: the model loaded with the correct src

* Compute the sign distance map

The sign distance map is computed in the notebook [[file:notebooks/Distance_map.ipynb]]. We use the method ~scipy.ndimage.distance_transform_bf~ to compute the distance [[https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.distance_transform_bf.html][(doc link)]].

